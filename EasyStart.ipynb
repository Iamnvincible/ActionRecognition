{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two-stream-action-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from random import randint\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import dataloader\n",
    "from utils import *\n",
    "from network import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify **path** and **ucf_list** fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> (Training video, Validation video):( 9537 3783 )\n"
     ]
    }
   ],
   "source": [
    "data_loader = dataloader.spatial_dataloader(\n",
    "                        BATCH_SIZE=32,\n",
    "                        num_workers=8,\n",
    "                        path='/mnt/act/jpegs_256',\n",
    "                        ucf_list ='/home/lin/two-stream-action-recognition/UCF_list/',\n",
    "                        ucf_split ='01', \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> sampling testing frames\n",
      "==> Training data : 9537 frames\n",
      "torch.Size([3, 224, 224])\n",
      "==> Validation data : 71877 frames\n",
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, test_video = data_loader.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the **resume** to the pre-trained model file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs=0\n",
    "lr=5e-4\n",
    "batch_size=32\n",
    "resume='/home/lin/model_best.pth.tar'\n",
    "start_epoch=0\n",
    "evaluate='evaluate'\n",
    "train_loader=train_loader\n",
    "test_loader=test_loader\n",
    "test_video=test_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet101(pretrained= True, channel=3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=0.9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1,verbose=True)\n",
    "tempmodel = model\n",
    "# if you want to run on multi GPUs, uncomment next line and set device_ids.\n",
    "#model = nn.DataParallel(model,device_ids=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> loading checkpoint '/home/lin/model_best.pth.tar'\n",
      "==> loaded checkpoint '/home/lin/model_best.pth.tar' (epoch 31) (best_prec1 82.1305847168)\n"
     ]
    }
   ],
   "source": [
    "if resume:\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"==> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        tempmodel.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"==> loaded checkpoint '{}' (epoch {}) (best_prec1 {})\".format(resume, checkpoint['epoch'], best_prec1))\n",
    "    else:\n",
    "        print(\"==> no checkpoint found at '{}'\".format(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame2_video_level_accuracy():      \n",
    "    correct = 0\n",
    "    video_level_preds = np.zeros((len(dic_video_level_preds),101))\n",
    "    video_level_labels = np.zeros(len(dic_video_level_preds))\n",
    "    ii=0\n",
    "    for name in sorted(dic_video_level_preds.keys()):\n",
    "    \n",
    "        preds = dic_video_level_preds[name]\n",
    "        label = int(test_video[name])-1\n",
    "            \n",
    "        video_level_preds[ii,:] = preds\n",
    "        video_level_labels[ii] = label\n",
    "        ii+=1         \n",
    "        if np.argmax(preds) == (label):\n",
    "            correct+=1\n",
    "\n",
    "    #top1 top5\n",
    "    video_level_labels = torch.from_numpy(video_level_labels).long()\n",
    "    video_level_preds = torch.from_numpy(video_level_preds).float()\n",
    "        \n",
    "    top1,top5 = accuracy(video_level_preds, video_level_labels, topk=(1,5))\n",
    "    loss = criterion(Variable(video_level_preds).cuda(), Variable(video_level_labels).cuda())     \n",
    "                        \n",
    "    top1 = float(top1.numpy())\n",
    "    top5 = float(top5.numpy())\n",
    "        \n",
    "    #print(' * Video level Prec@1 {top1:.3f}, Video level Prec@5 {top5:.3f}'.format(top1=top1, top5=top5))\n",
    "    return top1,top5,loss.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_video_level_preds={}\n",
    "def validate_1epoch():\n",
    "    print('==> Epoch:[{0}/{1}][validation stage]'.format(epoch, nb_epochs))\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    #dic_video_level_preds={}\n",
    "    end = time.time()\n",
    "    progress = tqdm(test_loader)\n",
    "    print type(progress)\n",
    "    for i, (keys,data,label) in enumerate(progress):\n",
    "        print keys,label\n",
    "        label = label.cuda(async=True)\n",
    "        data_var = Variable(data, volatile=True).cuda(async=True)\n",
    "        label_var = Variable(label, volatile=True).cuda(async=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(data_var)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        #Calculate video level prediction\n",
    "        preds = output.data.cpu().numpy()\n",
    "        #print preds\n",
    "        nb_data = preds.shape[0]\n",
    "        for j in range(nb_data):\n",
    "            videoName = keys[j].split('/',1)[0]\n",
    "            if videoName not in dic_video_level_preds.keys():\n",
    "                dic_video_level_preds[videoName] = preds[j,:]\n",
    "            else:\n",
    "                dic_video_level_preds[videoName] += preds[j,:]\n",
    "    video_top1, video_top5, video_loss = frame2_video_level_accuracy()\n",
    "    info = {'Epoch':[epoch],\n",
    "            'Batch Time':[round(batch_time.avg,3)],\n",
    "            'Loss':[round(video_loss,5)],\n",
    "            'Prec@1':[round(video_top1,3)],\n",
    "            'Prec@5':[round(video_top5,3)]}\n",
    "    record_info(info, 'record/spatial/rgb_test.csv','test')\n",
    "    return video_top1, video_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if evaluate:\n",
    "    epoch = 0\n",
    "    prec1, val_loss = validate_1epoch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
